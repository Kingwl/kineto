{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["0", 964761, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>Kernel: 964761us</b><br>Percentage: 18.22%</div>", 14376, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>Memcpy: 14376us</b><br>Percentage: 0.27%</div>", 467, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>Memset: 467us</b><br>Percentage: 0.01%</div>", 3728228, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>Runtime: 3728228us</b><br>Percentage: 70.4%</div>", 268948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>DataLoader: 268948us</b><br>Percentage: 5.08%</div>", 309561, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>CPU Exec: 309561us</b><br>Percentage: 5.85%</div>", 9079, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5295420us<br><b>Other: 9079us</b><br>Percentage: 0.17%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 5295420, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 964761, "extra": 18.22}, {"name": "Memcpy", "description": "", "value": 14376, "extra": 0.27}, {"name": "Memset", "description": "", "value": 467, "extra": 0.01}, {"name": "Runtime", "description": "", "value": 3728228, "extra": 70.4}, {"name": "DataLoader", "description": "", "value": 268948, "extra": 5.08}, {"name": "CPU Exec", "description": "", "value": 309561, "extra": 5.85}, {"name": "Other", "description": "", "value": 9079, "extra": 0.17}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 5.1% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "Number of Device(s)", "value": "1"}]}
{"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 512369], ["CudnnConvolutionBackward", 512369], ["aten::cudnn_convolution", 276514], ["aten::_convolution", 276514], ["aten::convolution", 276514], ["aten::conv2d", 276514], ["aten::cudnn_convolution_backward_weight", 258569], ["aten::cudnn_convolution_backward_input", 253800], ["aten::cudnn_batch_norm_backward", 57586], ["CudnnBatchNormBackward", 57586], ["aten::cudnn_batch_norm", 33538], ["aten::_batch_norm_impl_index", 33538], ["aten::batch_norm", 33538], ["aten::threshold_backward", 26617], ["ReluBackward1", 26617], ["aten::add_", 22561], ["aten::threshold_", 17883], ["aten::relu_", 17883], ["aten::copy_", 14372], ["aten::to", 13486], ["aten::max_pool2d_with_indices_backward", 5061], ["MaxPool2DWithIndicesBackward", 5061], ["torch::autograd::AccumulateGrad", 2868], ["aten::fill_", 2156], ["aten::zero_", 2150], ["aten::mul_", 1986], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::clone", 443], ["aten::add", 349], ["aten::mm", 288], ["AddmmBackward", 288], ["aten::mean", 255], ["aten::adaptive_avg_pool2d", 255], ["aten::addmm", 206], ["aten::div", 161], ["MeanBackward1", 161], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 63], ["aten::log_softmax", 63], ["aten::nll_loss_forward", 22], ["aten::nll_loss", 22], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 276514], ["aten::cudnn_convolution_backward_weight", 258569], ["aten::cudnn_convolution_backward_input", 253800], ["aten::cudnn_batch_norm_backward", 57586], ["aten::cudnn_batch_norm", 33538], ["aten::threshold_backward", 26617], ["aten::add_", 22561], ["aten::threshold_", 17883], ["aten::copy_", 14372], ["aten::max_pool2d_with_indices_backward", 4113], ["aten::fill_", 2156], ["aten::mul_", 1986], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 349], ["aten::mm", 288], ["aten::mean", 255], ["aten::addmm", 206], ["aten::div", 161], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 63], ["aten::nll_loss_forward", 22], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::conv2d", 1731907], ["aten::convolution", 1728290], ["aten::_convolution", 1724808], ["aten::cudnn_convolution", 1720621], ["aten::add", 1579353], ["CudnnConvolutionBackward", 619867], ["aten::cudnn_convolution_backward", 615814], ["aten::addmm", 478686], ["aten::cudnn_convolution_backward_weight", 371495], ["aten::cudnn_convolution_backward_input", 234340], ["aten::batch_norm", 128592], ["aten::_batch_norm_impl_index", 125115], ["aten::cudnn_batch_norm", 121919], ["aten::copy_", 87810], ["aten::add_", 83632], ["aten::to", 53979], ["torch::autograd::AccumulateGrad", 50534], ["aten::empty", 42482], ["aten::stack", 40630], ["aten::cat", 38776], ["aten::_cat", 38613], ["aten::div", 37542], ["CudnnBatchNormBackward", 36103], ["aten::contiguous", 35153], ["aten::cudnn_batch_norm_backward", 31590], ["aten::zero_", 30052], ["aten::mul_", 26511], ["aten::empty_strided", 18955], ["aten::fill_", 16574], ["ReluBackward1", 15700], ["aten::relu_", 15219], ["aten::clone", 13843], ["aten::threshold_backward", 13038], ["aten::new_empty_strided", 12143], ["aten::empty_like", 9889], ["aten::threshold_", 8318], ["aten::view", 4926], ["aten::resize_", 3336], ["aten::nll_loss", 3304], ["aten::permute", 3237], ["aten::nll_loss_forward", 3229], ["aten::set_", 2699], ["AddmmBackward", 2217], ["aten::randperm", 2155], ["aten::mm", 1577], ["aten::unsqueeze", 1214], ["aten::detach", 1045], ["aten::as_strided", 913], ["aten::max_pool2d", 837], ["aten::log_softmax", 828], ["MaxPool2DWithIndicesBackward", 828], ["NllLossBackward", 772], ["aten::_log_softmax", 736], ["aten::max_pool2d_with_indices", 733], ["aten::max_pool2d_with_indices_backward", 724], ["aten::t", 689], ["MeanBackward1", 677], ["aten::nll_loss_backward", 618], ["aten::zeros", 558], ["aten::adaptive_avg_pool2d", 523], ["detach", 464], ["LogSoftmaxBackward", 453], ["aten::mean", 445], ["aten::ones_like", 420], ["aten::_log_softmax_backward_data", 378], ["aten::zeros_like", 347], ["AddBackward0", 319], ["aten::transpose", 315], ["aten::reshape", 228], ["aten::flatten", 200], ["TBackward", 155], ["aten::expand", 140], ["ViewBackward", 127], ["aten::narrow", 90], ["aten::detach_", 66], ["aten::resize_as_", 57], ["aten::item", 52], ["aten::random_", 49], ["aten::slice", 49], ["aten::conj", 48], ["detach_", 31], ["aten::_local_scalar_dense", 19], ["aten::scalar_tensor", 7], ["aten::is_floating_point", 4]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 1710098], ["aten::add", 1579353], ["aten::addmm", 478563], ["aten::cudnn_convolution_backward_weight", 363604], ["aten::cudnn_convolution_backward_input", 229493], ["aten::cudnn_batch_norm", 107221], ["aten::copy_", 87810], ["aten::add_", 83632], ["aten::empty", 42482], ["aten::_cat", 38408], ["aten::div", 32732], ["aten::mul_", 26511], ["aten::cudnn_batch_norm_backward", 24314], ["aten::empty_strided", 18955], ["aten::fill_", 16574], ["aten::zero_", 13661], ["aten::threshold_backward", 11114], ["aten::cudnn_convolution_backward", 9979], ["aten::threshold_", 8318], ["torch::autograd::AccumulateGrad", 8100], ["aten::relu_", 6901], ["aten::to", 4965], ["aten::view", 4926], ["CudnnBatchNormBackward", 4513], ["aten::empty_like", 4219], ["aten::_convolution", 4187], ["CudnnConvolutionBackward", 4053], ["aten::conv2d", 3617], ["aten::convolution", 3482], ["aten::batch_norm", 3477], ["aten::resize_", 3336], ["aten::clone", 3257], ["aten::nll_loss_forward", 3229], ["aten::_batch_norm_impl_index", 3196], ["aten::new_empty_strided", 2835], ["aten::permute", 2783], ["aten::set_", 2699], ["ReluBackward1", 2662], ["aten::contiguous", 1792], ["aten::mm", 1498], ["aten::randperm", 1072], ["aten::as_strided", 913], ["aten::unsqueeze", 886], ["aten::stack", 640], ["aten::nll_loss_backward", 618], ["aten::detach", 581], ["aten::max_pool2d_with_indices", 555], ["detach", 464], ["aten::zeros", 405], ["aten::mean", 398], ["aten::_log_softmax", 396], ["aten::t", 374], ["aten::max_pool2d_with_indices_backward", 320], ["AddBackward0", 319], ["aten::_log_softmax_backward_data", 264], ["aten::transpose", 221], ["AddmmBackward", 209], ["aten::cat", 163], ["NllLossBackward", 154], ["MeanBackward1", 123], ["aten::expand", 114], ["aten::max_pool2d", 104], ["MaxPool2DWithIndicesBackward", 104], ["aten::ones_like", 94], ["aten::log_softmax", 92], ["aten::adaptive_avg_pool2d", 78], ["aten::reshape", 75], ["aten::nll_loss", 75], ["LogSoftmaxBackward", 75], ["aten::flatten", 62], ["aten::zeros_like", 59], ["aten::random_", 49], ["aten::conj", 48], ["aten::resize_as_", 46], ["aten::narrow", 41], ["aten::slice", 38], ["ViewBackward", 37], ["aten::detach_", 35], ["TBackward", 35], ["aten::item", 33], ["detach_", 31], ["aten::_local_scalar_dense", 19], ["aten::scalar_tensor", 7], ["aten::is_floating_point", 4]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 318, 276514, 276514, 1710098, 1720621], ["aten::cudnn_convolution_backward_weight", 318, 258569, 258569, 363604, 371495], ["aten::cudnn_convolution_backward_input", 312, 253800, 253800, 229493, 234340], ["aten::cudnn_batch_norm_backward", 318, 57586, 57586, 24314, 31590], ["aten::cudnn_batch_norm", 318, 33538, 33538, 107221, 121919], ["aten::threshold_backward", 294, 26617, 26617, 11114, 13038], ["aten::add_", 2672, 22561, 22561, 83632, 83632], ["aten::threshold_", 294, 17883, 17883, 8318, 8318], ["aten::copy_", 910, 14372, 14372, 87810, 87810], ["aten::max_pool2d_with_indices_backward", 6, 4113, 5061, 320, 724], ["aten::fill_", 817, 2156, 2156, 16574, 16574], ["aten::mul_", 805, 1986, 1986, 26511, 26511], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 555, 733], ["aten::add", 318, 349, 349, 1579353, 1579353], ["aten::mm", 12, 288, 288, 1498, 1577], ["aten::mean", 6, 255, 255, 398, 445], ["aten::addmm", 6, 206, 206, 478563, 478686], ["aten::div", 198, 161, 161, 32732, 37542], ["aten::_log_softmax_backward_data", 6, 64, 64, 264, 378], ["aten::_log_softmax", 6, 63, 63, 396, 736], ["aten::nll_loss_forward", 6, 22, 22, 3229, 3229], ["aten::nll_loss_backward", 6, 18, 18, 618, 618], ["aten::empty", 5739, 0, 0, 42482, 42482], ["aten::random_", 2, 0, 0, 49, 49], ["aten::is_floating_point", 2, 0, 0, 4, 4], ["aten::_local_scalar_dense", 2, 0, 0, 19, 19], ["aten::item", 2, 0, 0, 33, 52], ["aten::zero_", 829, 0, 2150, 13661, 30052], ["aten::zeros", 18, 0, 0, 405, 558], ["aten::scalar_tensor", 1, 0, 0, 7, 7], ["aten::resize_", 1928, 0, 0, 3336, 3336], ["aten::randperm", 2, 0, 0, 1072, 2155], ["aten::set_", 192, 0, 0, 2699, 2699], ["aten::view", 840, 0, 0, 4926, 4926], ["aten::as_strided", 432, 0, 0, 913, 913], ["aten::permute", 192, 0, 0, 2783, 3237], ["aten::empty_like", 534, 0, 0, 4219, 9889], ["aten::contiguous", 192, 0, 0, 1792, 35153], ["aten::empty_strided", 724, 0, 0, 18955, 18955], ["aten::to", 408, 0, 13486, 4965, 53979], ["aten::unsqueeze", 192, 0, 0, 886, 1214], ["aten::slice", 6, 0, 0, 38, 49], ["aten::narrow", 6, 0, 0, 41, 90], ["aten::_cat", 6, 0, 0, 38408, 38613], ["aten::cat", 6, 0, 0, 163, 38776], ["aten::stack", 6, 0, 0, 640, 40630], ["detach_", 6, 0, 0, 31, 31], ["aten::detach_", 6, 0, 0, 35, 66], ["aten::_convolution", 318, 0, 276514, 4187, 1724808], ["aten::convolution", 318, 0, 276514, 3482, 1728290], ["aten::conv2d", 318, 0, 276514, 3617, 1731907], ["aten::_batch_norm_impl_index", 318, 0, 33538, 3196, 125115], ["aten::batch_norm", 318, 0, 33538, 3477, 128592], ["aten::relu_", 294, 0, 17883, 6901, 15219], ["aten::max_pool2d", 6, 0, 1341, 104, 837], ["aten::adaptive_avg_pool2d", 6, 0, 255, 78, 523], ["aten::reshape", 12, 0, 0, 75, 228], ["aten::flatten", 6, 0, 0, 62, 200], ["aten::transpose", 30, 0, 0, 221, 315], ["aten::t", 30, 0, 0, 374, 689], ["aten::expand", 12, 0, 0, 114, 140], ["aten::log_softmax", 6, 0, 63, 92, 828], ["aten::nll_loss", 6, 0, 22, 75, 3304], ["aten::ones_like", 6, 0, 6, 94, 420], ["aten::clone", 161, 0, 443, 3257, 13843], ["detach", 161, 0, 0, 464, 464], ["aten::detach", 161, 0, 0, 581, 1045], ["NllLossBackward", 6, 0, 18, 154, 772], ["LogSoftmaxBackward", 6, 0, 64, 75, 453], ["aten::conj", 12, 0, 0, 48, 48], ["AddmmBackward", 6, 0, 288, 209, 2217], ["aten::new_empty_strided", 161, 0, 0, 2835, 12143], ["torch::autograd::AccumulateGrad", 966, 0, 2868, 8100, 50534], ["TBackward", 6, 0, 0, 35, 155], ["ViewBackward", 6, 0, 0, 37, 127], ["MeanBackward1", 6, 0, 161, 123, 677], ["ReluBackward1", 294, 0, 26617, 2662, 15700], ["AddBackward0", 96, 0, 0, 319, 319], ["CudnnBatchNormBackward", 318, 0, 57586, 4513, 36103], ["aten::cudnn_convolution_backward", 318, 0, 512369, 9979, 615814], ["CudnnConvolutionBackward", 318, 0, 512369, 4053, 619867], ["aten::zeros_like", 6, 0, 948, 59, 347], ["aten::resize_as_", 6, 0, 0, 46, 57], ["MaxPool2DWithIndicesBackward", 6, 0, 5061, 104, 828]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 206, 113082, 549, 1201, 150], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 196, 99102, 506, 1416, 380], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 264, 55287, 209, 850, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 588, 44500, 76, 395, 6], ["volta_cgemm_32x32_tn", 42, 44326, 1055, 3147, 214], ["volta_gcgemm_32x32_nt", 139, 41631, 300, 2233, 22], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 74, 38396, 519, 935, 361], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 2768, 37935, 14, 396, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 72, 33576, 466, 894, 385], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 60, 28442, 474, 731, 327], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26374, 176, 435, 50], ["volta_sgemm_128x64_nt", 128, 24816, 194, 677, 156], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 24, 23300, 971, 1393, 884], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 44, 17208, 391, 774, 361], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 24, 15055, 627, 1009, 442], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 20, 13927, 696, 885, 665], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13564, 411, 1388, 85], ["volta_scudnn_128x64_relu_interior_nn_v1", 41, 12936, 316, 687, 93], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12529, 298, 1583, 34], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 37, 12294, 332, 547, 265], ["volta_sgemm_128x64_nn", 64, 12220, 191, 208, 156], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 18, 10823, 601, 997, 207], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 17, 10754, 633, 879, 142], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 17, 10352, 609, 731, 335], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 10019, 313, 1655, 8], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 15, 9447, 630, 1111, 363], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8341, 417, 1638, 53], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 212, 8074, 38, 160, 6], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7736, 258, 937, 88], ["volta_scudnn_128x128_relu_medium_nn_v1", 26, 7518, 289, 454, 269], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 10, 7502, 750, 872, 667], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7164, 43, 97, 14], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 9, 6839, 760, 777, 740], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6497, 309, 1685, 34], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 35, 6460, 185, 463, 80], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6360, 145, 300, 15], ["volta_cgemm_64x32_tn", 2, 6353, 3176, 3178, 3175], ["volta_scudnn_128x64_relu_medium_nn_v1", 10, 6274, 627, 705, 388], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 128, 5560, 43, 113, 20], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 128, 5185, 41, 137, 17], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 19, 5181, 273, 281, 269], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 8, 4980, 622, 744, 570], ["volta_scudnn_128x64_relu_small_nn_v1", 15, 4669, 311, 652, 268], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4614, 41, 235, 13], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4584, 573, 1754, 16], ["volta_scudnn_128x128_stridedB_small_nn_v1", 8, 4575, 572, 878, 525], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 6, 4113, 686, 693, 683], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 13, 4089, 315, 328, 300], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4046, 270, 762, 120], ["volta_scudnn_128x128_relu_interior_nn_v1", 7, 3987, 570, 616, 550], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3554, 1185, 1272, 1107], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3498, 109, 233, 34], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3219, 3219, 3219, 3219], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 3006, 35, 122, 23], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 128, 2833, 22, 72, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 64, 2794, 44, 143, 21], ["volta_scudnn_128x64_stridedB_small_nn_v1", 10, 2698, 270, 692, 94], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 64, 2593, 41, 136, 17], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2375, 264, 845, 78], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2331, 777, 891, 566], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2294, 42, 75, 19], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2223, 97, 197, 38], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 817, 2156, 3, 158, 0], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2047, 512, 528, 492], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 805, 1986, 2, 24, 1], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 1960, 653, 691, 581], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1670, 1670, 1670, 1670], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1623, 1623, 1623, 1623], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1520, 127, 407, 20], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 64, 1425, 22, 65, 3], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4, 1331, 333, 525, 140], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1280, 640, 643, 637], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1079, 1079, 1079, 1079], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 738, 738, 738, 738], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 695, 695, 695, 695], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 609, 609, 609, 609], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 201, 565, 3, 7, 1], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 560, 560, 560, 560], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 523, 523, 523, 523], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 520, 520, 520, 520], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 508, 85, 139, 54], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 349, 1, 3, 1], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 10, 330, 33, 74, 9], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 314, 314, 314, 314], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 44, 255, 6, 46, 2], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 255, 42, 43, 42], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 161, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_nn", 6, 158, 26, 27, 26], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 102, 153, 2, 3, 1], ["volta_sgemm_64x32_sliced1x4_tn", 6, 147, 24, 27, 24], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 102, 142, 1, 2, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 88, 118, 1, 2, 1], ["volta_sgemm_128x32_nt", 6, 116, 19, 20, 19], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 6, 113, 19, 36, 9], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 64, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 63, 10, 11, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 36, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 35, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 22, 4, 5, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 113082.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 99102.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 55287.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 44500.0], ["volta_cgemm_32x32_tn", 44326.0], ["volta_gcgemm_32x32_nt", 41631.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 38396.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 37935.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 33576.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 28442.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26374.0], ["volta_sgemm_128x64_nt", 24816.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 23300.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 17208.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 15055.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 13927.0], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 13564.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 12936.0], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 12529.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 12294.0], ["volta_sgemm_128x64_nn", 12220.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 10823.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 10754.0], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 10352.0], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 10019.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 9447.0], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8341.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 8074.0], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 7736.0], ["volta_scudnn_128x128_relu_medium_nn_v1", 7518.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 7502.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7164.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 6839.0], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 6497.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6460.0], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 6360.0], ["volta_cgemm_64x32_tn", 6353.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 6274.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 5560.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 5185.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5181.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 4980.0], ["volta_scudnn_128x64_relu_small_nn_v1", 4669.0], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 4614.0], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 4584.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 4575.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4113.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4089.0], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 4046.0], ["volta_scudnn_128x128_relu_interior_nn_v1", 3987.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3554.0], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 3498.0], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 3219.0], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 3006.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2833.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2794.0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 2698.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2593.0], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 2375.0], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 2331.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2294.0], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 2223.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2156.0], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 2047.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1986.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 1960.0], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1670.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1623.0], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 1520.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1425.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 1331.0], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 1280.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1079.0], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 738.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 695.0], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 609.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 565.0], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 560.0], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 523.0], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 520.0], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 508.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 349.0], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 330.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 314.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 255.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 255.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 161.0], ["volta_sgemm_64x32_sliced1x4_nn", 158.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 153.0], ["volta_sgemm_64x32_sliced1x4_tn", 147.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 142.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 118.0], ["volta_sgemm_128x32_nt", 116.0], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 113.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 64.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 63.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 36.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 35.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 22.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 12.0]]}}
{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["0", 968129, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>Kernel: 968129us</b><br>Percentage: 16.46%</div>", 20898, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>Memcpy: 20898us</b><br>Percentage: 0.36%</div>", 470, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>Memset: 470us</b><br>Percentage: 0.01%</div>", 4401712, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>Runtime: 4401712us</b><br>Percentage: 74.85%</div>", 82000, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>DataLoader: 82000us</b><br>Percentage: 1.39%</div>", 322717, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>CPU Exec: 322717us</b><br>Percentage: 5.49%</div>", 84952, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 0<br>Total: 5880878us<br><b>Other: 84952us</b><br>Percentage: 1.44%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 5880878, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 968129, "extra": 16.46}, {"name": "Memcpy", "description": "", "value": 20898, "extra": 0.36}, {"name": "Memset", "description": "", "value": 470, "extra": 0.01}, {"name": "Runtime", "description": "", "value": 4401712, "extra": 74.85}, {"name": "DataLoader", "description": "", "value": 82000, "extra": 1.39}, {"name": "CPU Exec", "description": "", "value": 322717, "extra": 5.49}, {"name": "Other", "description": "", "value": 84952, "extra": 1.44}]}], "recommendations": "<ul><li>N/A</li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "Number of Device(s)", "value": "1"}]}
{"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 512272], ["CudnnConvolutionBackward", 512272], ["aten::cudnn_convolution", 279825], ["aten::_convolution", 279825], ["aten::convolution", 279825], ["aten::conv2d", 279825], ["aten::cudnn_convolution_backward_weight", 258703], ["aten::cudnn_convolution_backward_input", 253569], ["aten::cudnn_batch_norm_backward", 57608], ["CudnnBatchNormBackward", 57608], ["aten::cudnn_batch_norm", 33571], ["aten::_batch_norm_impl_index", 33571], ["aten::batch_norm", 33571], ["aten::threshold_backward", 26622], ["ReluBackward1", 26622], ["aten::add_", 22543], ["aten::copy_", 20894], ["aten::to", 20008], ["aten::threshold_", 17916], ["aten::relu_", 17916], ["aten::max_pool2d_with_indices_backward", 5067], ["MaxPool2DWithIndicesBackward", 5067], ["torch::autograd::AccumulateGrad", 2866], ["aten::fill_", 2178], ["aten::zero_", 2172], ["aten::mul_", 1985], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::clone", 443], ["aten::add", 346], ["aten::mm", 287], ["AddmmBackward", 287], ["aten::mean", 259], ["aten::adaptive_avg_pool2d", 259], ["aten::addmm", 202], ["aten::div", 161], ["MeanBackward1", 161], ["aten::_log_softmax_backward_data", 65], ["LogSoftmaxBackward", 65], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 22], ["aten::nll_loss", 22], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution", 279825], ["aten::cudnn_convolution_backward_weight", 258703], ["aten::cudnn_convolution_backward_input", 253569], ["aten::cudnn_batch_norm_backward", 57608], ["aten::cudnn_batch_norm", 33571], ["aten::threshold_backward", 26622], ["aten::add_", 22543], ["aten::copy_", 20894], ["aten::threshold_", 17916], ["aten::max_pool2d_with_indices_backward", 4119], ["aten::fill_", 2178], ["aten::mul_", 1985], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 346], ["aten::mm", 287], ["aten::mean", 259], ["aten::addmm", 202], ["aten::div", 161], ["aten::_log_softmax_backward_data", 65], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 22], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add", 2139516], ["aten::conv2d", 1833964], ["aten::convolution", 1830115], ["aten::_convolution", 1826470], ["aten::cudnn_convolution", 1822134], ["CudnnConvolutionBackward", 628045], ["aten::cudnn_convolution_backward", 623917], ["aten::addmm", 482328], ["aten::cudnn_convolution_backward_weight", 378900], ["aten::cudnn_convolution_backward_input", 234459], ["aten::batch_norm", 128257], ["aten::_batch_norm_impl_index", 124471], ["aten::cudnn_batch_norm", 121175], ["aten::add_", 78129], ["aten::copy_", 57130], ["aten::to", 56380], ["torch::autograd::AccumulateGrad", 47959], ["CudnnBatchNormBackward", 44393], ["aten::empty", 40817], ["aten::cudnn_batch_norm_backward", 36591], ["aten::mul_", 28459], ["aten::zero_", 27231], ["aten::empty_strided", 22013], ["ReluBackward1", 17187], ["aten::fill_", 16030], ["aten::relu_", 15904], ["aten::clone", 14539], ["aten::threshold_backward", 14524], ["aten::randperm", 10943], ["aten::new_empty_strided", 8516], ["aten::threshold_", 8341], ["aten::empty_like", 8259], ["aten::resize_", 3467], ["aten::nll_loss", 3268], ["aten::nll_loss_forward", 3194], ["aten::view", 2894], ["AddmmBackward", 2494], ["aten::mm", 1797], ["aten::detach", 1248], ["aten::item", 1018], ["aten::_local_scalar_dense", 991], ["MaxPool2DWithIndicesBackward", 925], ["aten::log_softmax", 847], ["NllLossBackward", 835], ["aten::max_pool2d_with_indices_backward", 826], ["aten::max_pool2d", 801], ["aten::_log_softmax", 758], ["aten::t", 717], ["aten::max_pool2d_with_indices", 698], ["aten::nll_loss_backward", 692], ["MeanBackward1", 680], ["aten::zeros", 606], ["aten::adaptive_avg_pool2d", 588], ["detach", 537], ["LogSoftmaxBackward", 482], ["aten::mean", 476], ["aten::div", 462], ["aten::ones_like", 435], ["aten::_log_softmax_backward_data", 403], ["aten::zeros_like", 390], ["aten::transpose", 335], ["AddBackward0", 329], ["aten::reshape", 250], ["aten::flatten", 238], ["aten::expand", 171], ["aten::detach_", 163], ["TBackward", 153], ["aten::set_", 143], ["ViewBackward", 131], ["aten::as_strided", 119], ["aten::random_", 99], ["aten::resize_as_", 79], ["detach_", 75], ["aten::conj", 59], ["aten::scalar_tensor", 7], ["aten::is_floating_point", 5]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add", 2139516], ["aten::cudnn_convolution", 1811273], ["aten::addmm", 482185], ["aten::cudnn_convolution_backward_weight", 370444], ["aten::cudnn_convolution_backward_input", 229287], ["aten::cudnn_batch_norm", 106170], ["aten::add_", 78129], ["aten::copy_", 57130], ["aten::empty", 40817], ["aten::cudnn_batch_norm_backward", 29206], ["aten::mul_", 28459], ["aten::empty_strided", 22013], ["aten::fill_", 16030], ["aten::threshold_backward", 12544], ["aten::zero_", 11400], ["aten::cudnn_convolution_backward", 10558], ["aten::threshold_", 8341], ["torch::autograd::AccumulateGrad", 8084], ["CudnnBatchNormBackward", 7802], ["aten::relu_", 7563], ["aten::randperm", 5467], ["aten::clone", 4974], ["aten::_convolution", 4336], ["CudnnConvolutionBackward", 4128], ["aten::conv2d", 3849], ["aten::batch_norm", 3786], ["aten::convolution", 3645], ["aten::resize_", 3467], ["aten::_batch_norm_impl_index", 3296], ["aten::nll_loss_forward", 3194], ["aten::empty_like", 3150], ["aten::view", 2894], ["ReluBackward1", 2663], ["aten::mm", 1708], ["aten::new_empty_strided", 1494], ["aten::_local_scalar_dense", 991], ["aten::detach", 711], ["aten::nll_loss_backward", 692], ["aten::max_pool2d_with_indices", 548], ["detach", 537], ["aten::zeros", 436], ["aten::mean", 429], ["aten::div", 420], ["aten::_log_softmax", 416], ["aten::t", 382], ["aten::max_pool2d_with_indices_backward", 357], ["AddBackward0", 329], ["aten::_log_softmax_backward_data", 292], ["aten::to", 273], ["aten::transpose", 246], ["AddmmBackward", 219], ["aten::set_", 143], ["NllLossBackward", 143], ["aten::expand", 141], ["aten::as_strided", 119], ["aten::adaptive_avg_pool2d", 112], ["aten::ones_like", 107], ["aten::max_pool2d", 103], ["MeanBackward1", 101], ["aten::random_", 99], ["MaxPool2DWithIndicesBackward", 99], ["aten::log_softmax", 89], ["aten::detach_", 88], ["aten::flatten", 83], ["LogSoftmaxBackward", 79], ["detach_", 75], ["aten::reshape", 75], ["aten::nll_loss", 74], ["aten::zeros_like", 70], ["aten::resize_as_", 68], ["aten::conj", 59], ["ViewBackward", 36], ["TBackward", 33], ["aten::item", 27], ["aten::scalar_tensor", 7], ["aten::is_floating_point", 5]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution", 318, 279825, 279825, 1811273, 1822134], ["aten::cudnn_convolution_backward_weight", 318, 258703, 258703, 370444, 378900], ["aten::cudnn_convolution_backward_input", 312, 253569, 253569, 229287, 234459], ["aten::cudnn_batch_norm_backward", 318, 57608, 57608, 29206, 36591], ["aten::cudnn_batch_norm", 318, 33571, 33571, 106170, 121175], ["aten::threshold_backward", 294, 26622, 26622, 12544, 14524], ["aten::add_", 2672, 22543, 22543, 78129, 78129], ["aten::copy_", 334, 20894, 20894, 57130, 57130], ["aten::threshold_", 294, 17916, 17916, 8341, 8341], ["aten::max_pool2d_with_indices_backward", 6, 4119, 5067, 357, 826], ["aten::fill_", 817, 2178, 2178, 16030, 16030], ["aten::mul_", 805, 1985, 1985, 28459, 28459], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 548, 698], ["aten::add", 318, 346, 346, 2139516, 2139516], ["aten::mm", 12, 287, 287, 1708, 1797], ["aten::mean", 6, 259, 259, 429, 476], ["aten::addmm", 6, 202, 202, 482185, 482328], ["aten::div", 6, 161, 161, 420, 462], ["aten::_log_softmax_backward_data", 6, 65, 65, 292, 403], ["aten::_log_softmax", 6, 60, 60, 416, 758], ["aten::nll_loss_forward", 6, 22, 22, 3194, 3194], ["aten::nll_loss_backward", 6, 18, 18, 692, 692], ["aten::empty", 5165, 0, 0, 40817, 40817], ["aten::random_", 2, 0, 0, 99, 99], ["aten::is_floating_point", 2, 0, 0, 5, 5], ["aten::_local_scalar_dense", 2, 0, 0, 991, 991], ["aten::item", 2, 0, 0, 27, 1018], ["aten::scalar_tensor", 1, 0, 0, 7, 7], ["aten::resize_", 1922, 0, 0, 3467, 3467], ["aten::randperm", 2, 0, 0, 5467, 10943], ["aten::zero_", 829, 0, 2172, 11400, 27231], ["aten::zeros", 18, 0, 0, 436, 606], ["aten::to", 32, 0, 20008, 273, 56380], ["detach_", 14, 0, 0, 75, 75], ["aten::detach_", 14, 0, 0, 88, 163], ["aten::set_", 14, 0, 0, 143, 143], ["aten::empty_strided", 340, 0, 0, 22013, 22013], ["aten::_convolution", 318, 0, 279825, 4336, 1826470], ["aten::convolution", 318, 0, 279825, 3645, 1830115], ["aten::conv2d", 318, 0, 279825, 3849, 1833964], ["aten::empty_like", 342, 0, 0, 3150, 8259], ["aten::view", 648, 0, 0, 2894, 2894], ["aten::_batch_norm_impl_index", 318, 0, 33571, 3296, 124471], ["aten::batch_norm", 318, 0, 33571, 3786, 128257], ["aten::relu_", 294, 0, 17916, 7563, 15904], ["aten::max_pool2d", 6, 0, 1341, 103, 801], ["aten::adaptive_avg_pool2d", 6, 0, 259, 112, 588], ["aten::reshape", 12, 0, 0, 75, 250], ["aten::flatten", 6, 0, 0, 83, 238], ["aten::as_strided", 42, 0, 0, 119, 119], ["aten::transpose", 30, 0, 0, 246, 335], ["aten::t", 30, 0, 0, 382, 717], ["aten::expand", 12, 0, 0, 141, 171], ["aten::log_softmax", 6, 0, 60, 89, 847], ["aten::nll_loss", 6, 0, 22, 74, 3268], ["aten::ones_like", 6, 0, 6, 107, 435], ["aten::clone", 161, 0, 443, 4974, 14539], ["detach", 161, 0, 0, 537, 537], ["aten::detach", 161, 0, 0, 711, 1248], ["NllLossBackward", 6, 0, 18, 143, 835], ["LogSoftmaxBackward", 6, 0, 65, 79, 482], ["aten::conj", 12, 0, 0, 59, 59], ["AddmmBackward", 6, 0, 287, 219, 2494], ["aten::new_empty_strided", 161, 0, 0, 1494, 8516], ["torch::autograd::AccumulateGrad", 966, 0, 2866, 8084, 47959], ["TBackward", 6, 0, 0, 33, 153], ["ViewBackward", 6, 0, 0, 36, 131], ["MeanBackward1", 6, 0, 161, 101, 680], ["ReluBackward1", 294, 0, 26622, 2663, 17187], ["AddBackward0", 96, 0, 0, 329, 329], ["CudnnBatchNormBackward", 318, 0, 57608, 7802, 44393], ["aten::cudnn_convolution_backward", 318, 0, 512272, 10558, 623917], ["CudnnConvolutionBackward", 318, 0, 512272, 4128, 628045], ["aten::zeros_like", 6, 0, 948, 70, 390], ["aten::resize_as_", 6, 0, 0, 68, 79], ["MaxPool2DWithIndicesBackward", 6, 0, 5067, 99, 925]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 206, 112823, 548, 1198, 149], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 196, 99201, 506, 1455, 380], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 264, 55303, 209, 859, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 588, 44538, 76, 394, 6], ["volta_cgemm_32x32_tn", 42, 44400, 1057, 3146, 217], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 96, 44022, 459, 963, 384], ["volta_gcgemm_32x32_nt", 139, 41535, 299, 2233, 21], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 74, 38206, 516, 937, 360], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 2768, 37906, 14, 395, 1], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 60, 28529, 475, 739, 329], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26433, 176, 437, 50], ["volta_sgemm_128x64_nt", 128, 24826, 194, 676, 156], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 24, 23310, 971, 1395, 877], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 44, 17227, 392, 772, 361], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 24, 15034, 626, 1010, 442], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 20, 13931, 697, 888, 664], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 33, 13569, 411, 1393, 84], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 42, 12567, 299, 1587, 35], ["volta_scudnn_128x64_relu_interior_nn_v1", 35, 12380, 354, 677, 101], ["volta_sgemm_128x64_nn", 64, 12244, 191, 209, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 37, 12222, 330, 531, 260], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 18, 10841, 602, 1003, 207], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 17, 10754, 633, 879, 138], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 17, 10389, 611, 732, 334], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 32, 9996, 312, 1639, 8], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 15, 9395, 626, 1113, 364], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 20, 8332, 417, 1629, 51], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 212, 8061, 38, 160, 6], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 30, 7758, 259, 939, 87], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 10, 7421, 742, 871, 667], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7138, 42, 96, 14], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 9, 6838, 760, 778, 739], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 21, 6490, 309, 1678, 34], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 35, 6435, 184, 452, 78], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 44, 6401, 145, 308, 15], ["volta_cgemm_64x32_tn", 2, 6351, 3176, 3177, 3174], ["volta_scudnn_128x64_relu_medium_nn_v1", 10, 6270, 627, 705, 384], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 128, 5536, 43, 112, 18], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 19, 5240, 276, 303, 267], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 128, 5167, 40, 138, 17], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 8, 5009, 626, 694, 569], ["volta_scudnn_128x64_relu_small_nn_v1", 15, 4644, 310, 649, 266], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 112, 4613, 41, 241, 12], ["volta_scudnn_128x128_stridedB_small_nn_v1", 8, 4584, 573, 881, 527], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8, 4551, 569, 1747, 16], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 6, 4119, 686, 694, 684], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 13, 4094, 315, 329, 300], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 15, 4048, 270, 756, 121], ["volta_scudnn_128x128_relu_interior_nn_v1", 7, 3983, 569, 614, 548], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3, 3544, 1181, 1268, 1103], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 32, 3487, 109, 246, 34], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 1, 3245, 3245, 3245, 3245], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 87, 2959, 34, 126, 24], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 128, 2806, 22, 72, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 64, 2733, 43, 139, 20], ["volta_scudnn_128x64_stridedB_small_nn_v1", 10, 2584, 258, 692, 94], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 64, 2576, 40, 137, 17], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 9, 2368, 263, 832, 77], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 3, 2340, 780, 891, 568], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2300, 43, 75, 19], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 23, 2231, 97, 199, 44], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 10, 2193, 219, 529, 139], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 817, 2178, 3, 158, 0], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 4, 2052, 513, 526, 503], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 805, 1985, 2, 24, 1], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 3, 1956, 652, 687, 582], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1, 1654, 1654, 1654, 1654], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1630, 1630, 1630, 1630], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 12, 1501, 125, 406, 20], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 64, 1406, 22, 64, 3], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 226, 223], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 2, 1277, 638, 644, 633], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1, 1091, 1091, 1091, 1091], ["volta_scudnn_128x128_relu_medium_nn_v1", 2, 791, 396, 456, 335], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 1, 688, 688, 688, 688], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 1, 648, 648, 648, 648], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 584, 584, 584, 584], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 1, 568, 568, 568, 568], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 171, 541, 3, 6, 2], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 1, 520, 520, 520, 520], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 1, 519, 519, 519, 519], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 6, 510, 85, 141, 55], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 346, 1, 3, 1], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 10, 332, 33, 74, 10], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 1, 313, 313, 313, 313], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 259, 43, 46, 42], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 44, 250, 6, 46, 2], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 161, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_nn", 6, 157, 26, 27, 25], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 102, 150, 1, 2, 1], ["volta_sgemm_64x32_sliced1x4_tn", 6, 144, 24, 24, 24], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 102, 139, 1, 2, 1], ["volta_sgemm_128x32_nt", 6, 116, 19, 20, 19], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 88, 115, 1, 2, 1], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 6, 108, 18, 36, 9], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 65, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 49, 8, 9, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 35, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 35, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 22, 4, 5, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 112823.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 99201.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 55303.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 44538.0], ["volta_cgemm_32x32_tn", 44400.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 44022.0], ["volta_gcgemm_32x32_nt", 41535.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 38206.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 37906.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 28529.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26433.0], ["volta_sgemm_128x64_nt", 24826.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 23310.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 17227.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 15034.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 13931.0], ["void transpose_readWrite_alignment_kernel<float2, float2, 1, false, 6, 4, 4>(cublasTransposeParams<float2>, float2 const*, float2*, float2 const*)", 13569.0], ["void fft2d_r2c_16x16<float>(float2*, float const*, int, int, int, int, int, int, int, int)", 12567.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 12380.0], ["volta_sgemm_128x64_nn", 12244.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 12222.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 10841.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 10754.0], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 10389.0], ["void flip_filter<float, float>(float*, float const*, int, int, int, int)", 9996.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 9395.0], ["void fft2d_r2c_32x32<float, false, 1u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 8332.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 8061.0], ["void fft2d_r2c_64x64<float, true>(float2*, float const*, int, int, int, int, int, int, int, int)", 7758.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 7421.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7138.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 6838.0], ["void fft2d_c2r_16x16<float, false>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 6490.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6435.0], ["void fft1d_r2c_32<float, float, float2, false, false>(float2*, float const*, int, int3, int3, int2, int2)", 6401.0], ["volta_cgemm_64x32_tn", 6351.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 6270.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 5536.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5240.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 5167.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 5009.0], ["volta_scudnn_128x64_relu_small_nn_v1", 4644.0], ["void fft2d_r2c_32x32<float, false, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 4613.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 4584.0], ["void fft2d_r2c_32x32<float, false, 1u, true>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 4551.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4119.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4094.0], ["void fft2d_c2r_64x64<float, false, true>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)", 4048.0], ["volta_scudnn_128x128_relu_interior_nn_v1", 3983.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 5, 6, 4, 3, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 3544.0], ["void fft1d_c2r_32<float2, float, float, false, true, false, false>(float*, float2 const*, int, int3, int3, int2, int, float, float, float*, float*)", 3487.0], ["void cudnn::detail::dgrad_alg1_engine<float, 128, 6, 8, 3, 3, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, float, int)", 3245.0], ["void fft2d_c2r_32x32<float, true, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 2959.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2806.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2733.0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 2584.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2576.0], ["void fft2d_c2r_32x32<float, false, false, 1u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 2368.0], ["volta_scudnn_128x64_stridedB_splitK_interior_nn_v1", 2340.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2300.0], ["void fft2d_c2r_32x32<float, false, false, 0u, false, false>(float*, float2 const*, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)", 2231.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 2193.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2178.0], ["void pointwise_mult_and_sum_complex<float2, 8, 4>(float2*, float2*, float2*, int, int, int, int, int, float2)", 2052.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1985.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1", 1956.0], ["volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1", 1654.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 4, 6, 3, 2, 4, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1630.0], ["void fft1d_r2c_32<float, float, float2, true, false>(float2*, float const*, int, int3, int3, int2, int2)", 1501.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1406.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["volta_scudnn_128x64_stridedB_splitK_small_nn_v1", 1277.0], ["void cudnn::detail::dgrad2d_alg1_1<float, 0, 6, 7, 5, 4, 5, false, true>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int)", 1091.0], ["volta_scudnn_128x128_relu_medium_nn_v1", 791.0], ["void explicit_convolve_sgemm<float, int, 512, 6, 8, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 688.0], ["volta_scudnn_128x64_stridedB_medium_nn_v1", 648.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1", 584.0], ["volta_scudnn_128x64_stridedB_splitK_medium_nn_v1", 568.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 541.0], ["void cudnn::cnn::wgrad_alg1_engine<float, 128, 5, 5, 3, 3, 3, false, true>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, float, int, int, int*, int*, int, int)", 520.0], ["volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_medium_nhwc_tn_v1", 519.0], ["void fft2d_r2c_32x32<float, true, 0u, false>(float2*, float const*, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)", 510.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 346.0], ["void nchwToNhwcKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 332.0], ["volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1", 313.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 259.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 250.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 161.0], ["volta_sgemm_64x32_sliced1x4_nn", 157.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 150.0], ["volta_sgemm_64x32_sliced1x4_tn", 144.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 139.0], ["volta_sgemm_128x32_nt", 116.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 115.0], ["void nhwcToNchwKernel<float, float, float, true, false, (cudnnKernelDataType_t)0>(int, int, int, int, float const*, float*, float, float)", 108.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 65.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 49.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 35.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 35.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 22.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 12.0]]}}
{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 129520, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Kernel: 129520us</b><br>Percentage: 81.37%</div>", 1948, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Memcpy: 1948us</b><br>Percentage: 1.22%</div>", 90, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Memset: 90us</b><br>Percentage: 0.06%</div>", 3346, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Runtime: 3346us</b><br>Percentage: 2.1%</div>", 10482, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>DataLoader: 10482us</b><br>Percentage: 6.59%</div>", 12480, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>CPU Exec: 12480us</b><br>Percentage: 7.84%</div>", 1308, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 159174us<br><b>Other: 1308us</b><br>Percentage: 0.82%</div>"], ["6", 92970, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Kernel: 92970us</b><br>Percentage: 61.66%</div>", 2436, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Memcpy: 2436us</b><br>Percentage: 1.62%</div>", 63, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Memset: 63us</b><br>Percentage: 0.04%</div>", 3144, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Runtime: 3144us</b><br>Percentage: 2.09%</div>", 37456, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>DataLoader: 37456us</b><br>Percentage: 24.84%</div>", 13420, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>CPU Exec: 13420us</b><br>Percentage: 8.9%</div>", 1301, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 150790us<br><b>Other: 1301us</b><br>Percentage: 0.86%</div>"], ["7", 101813, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Kernel: 101813us</b><br>Percentage: 72.03%</div>", 2111, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Memcpy: 2111us</b><br>Percentage: 1.49%</div>", 70, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Memset: 70us</b><br>Percentage: 0.05%</div>", 1756, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Runtime: 1756us</b><br>Percentage: 1.24%</div>", 28987, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>DataLoader: 28987us</b><br>Percentage: 20.51%</div>", 5904, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>CPU Exec: 5904us</b><br>Percentage: 4.18%</div>", 705, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 141346us<br><b>Other: 705us</b><br>Percentage: 0.5%</div>"], ["8", 98964, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Kernel: 98964us</b><br>Percentage: 61.48%</div>", 2078, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Memcpy: 2078us</b><br>Percentage: 1.29%</div>", 68, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Memset: 68us</b><br>Percentage: 0.04%</div>", 2040, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Runtime: 2040us</b><br>Percentage: 1.27%</div>", 49981, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>DataLoader: 49981us</b><br>Percentage: 31.05%</div>", 7087, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>CPU Exec: 7087us</b><br>Percentage: 4.4%</div>", 745, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 160963us<br><b>Other: 745us</b><br>Percentage: 0.46%</div>"], ["9", 108112, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Kernel: 108112us</b><br>Percentage: 72.81%</div>", 2072, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Memcpy: 2072us</b><br>Percentage: 1.4%</div>", 74, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Memset: 74us</b><br>Percentage: 0.05%</div>", 2926, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Runtime: 2926us</b><br>Percentage: 1.97%</div>", 25411, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>DataLoader: 25411us</b><br>Percentage: 17.11%</div>", 9081, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>CPU Exec: 9081us</b><br>Percentage: 6.12%</div>", 809, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 148485us<br><b>Other: 809us</b><br>Percentage: 0.54%</div>"], ["10", 108661, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Kernel: 108661us</b><br>Percentage: 64.79%</div>", 2089, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Memcpy: 2089us</b><br>Percentage: 1.25%</div>", 74, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Memset: 74us</b><br>Percentage: 0.04%</div>", 4174, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Runtime: 4174us</b><br>Percentage: 2.49%</div>", 36220, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>DataLoader: 36220us</b><br>Percentage: 21.6%</div>", 14751, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>CPU Exec: 14751us</b><br>Percentage: 8.8%</div>", 1743, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 167712us<br><b>Other: 1743us</b><br>Percentage: 1.04%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 154745, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 106673, "extra": 68.93}, {"name": "Memcpy", "description": "", "value": 2122, "extra": 1.37}, {"name": "Memset", "description": "", "value": 73, "extra": 0.05}, {"name": "Runtime", "description": "", "value": 2898, "extra": 1.87}, {"name": "DataLoader", "description": "", "value": 31423, "extra": 20.31}, {"name": "CPU Exec", "description": "", "value": 10454, "extra": 6.76}, {"name": "Other", "description": "", "value": 1102, "extra": 0.71}]}], "recommendations": "<ul><li>This run has high time cost on input data loading. 20.3% of the step time is in DataLoader. You could try to set num_workers on DataLoader's construction and enable multi-processes on data loading. Reference: <a href =\"https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\" target=\"_blank\">Single- and Multi-process Data Loading</a></li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "Number of Device(s)", "value": "1"}]}
{"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 285514], ["CudnnConvolutionBackward", 285514], ["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::_convolution", 135735], ["aten::convolution", 135735], ["aten::conv2d", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["CudnnBatchNormBackward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::_batch_norm_impl_index", 33292], ["aten::batch_norm", 33292], ["aten::threshold_backward", 26258], ["ReluBackward1", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::relu_", 17759], ["aten::copy_", 12734], ["aten::to", 12734], ["aten::max_pool2d_with_indices_backward", 5046], ["MaxPool2DWithIndicesBackward", 5046], ["torch::autograd::AccumulateGrad", 2915], ["aten::fill_", 2414], ["aten::zero_", 2408], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 325], ["aten::mm", 295], ["AddmmBackward", 295], ["aten::mean", 256], ["aten::adaptive_avg_pool2d", 256], ["aten::addmm", 201], ["aten::div", 162], ["MeanBackward1", 162], ["aten::_log_softmax_backward_data", 64], ["LogSoftmaxBackward", 64], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss", 20], ["aten::nll_loss_backward", 18], ["NllLossBackward", 18], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 149670], ["aten::cudnn_convolution_backward_input", 135844], ["aten::cudnn_convolution", 135735], ["aten::cudnn_batch_norm_backward", 56884], ["aten::cudnn_batch_norm", 33292], ["aten::threshold_backward", 26258], ["aten::add_", 23357], ["aten::threshold_", 17759], ["aten::copy_", 12734], ["aten::max_pool2d_with_indices_backward", 4098], ["aten::fill_", 2414], ["aten::mul_", 2380], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 325], ["aten::mm", 295], ["aten::mean", 256], ["aten::addmm", 201], ["aten::div", 162], ["aten::_log_softmax_backward_data", 64], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 20], ["aten::nll_loss_backward", 18]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["CudnnConvolutionBackward", 90857], ["aten::cudnn_convolution_backward", 87104], ["aten::conv2d", 61610], ["aten::copy_", 60140], ["aten::convolution", 57644], ["aten::batch_norm", 55154], ["aten::_convolution", 53789], ["aten::_batch_norm_impl_index", 51122], ["aten::cudnn_convolution", 49275], ["aten::cudnn_batch_norm", 47638], ["aten::to", 46057], ["aten::cudnn_convolution_backward_weight", 39006], ["aten::cudnn_convolution_backward_input", 38583], ["aten::mul_", 36843], ["aten::zero_", 36160], ["torch::autograd::AccumulateGrad", 34208], ["aten::empty", 33098], ["aten::stack", 33058], ["CudnnBatchNormBackward", 32186], ["aten::cat", 31169], ["aten::_cat", 30970], ["aten::div", 30671], ["aten::cudnn_batch_norm_backward", 27883], ["aten::contiguous", 24479], ["aten::fill_", 21081], ["aten::relu_", 16620], ["ReluBackward1", 15142], ["aten::add", 14945], ["aten::threshold_backward", 12601], ["aten::threshold_", 9128], ["aten::empty_like", 8255], ["aten::view", 4811], ["aten::resize_", 3415], ["aten::permute", 3161], ["aten::set_", 2994], ["aten::empty_strided", 1725], ["AddmmBackward", 1462], ["aten::unsqueeze", 1293], ["aten::addmm", 1274], ["aten::as_strided", 948], ["aten::mm", 847], ["MaxPool2DWithIndicesBackward", 763], ["aten::max_pool2d", 732], ["NllLossBackward", 719], ["aten::max_pool2d_with_indices_backward", 686], ["aten::t", 664], ["aten::zeros", 651], ["aten::max_pool2d_with_indices", 644], ["MeanBackward1", 606], ["aten::nll_loss_backward", 590], ["aten::adaptive_avg_pool2d", 566], ["aten::log_softmax", 527], ["aten::nll_loss", 500], ["aten::mean", 484], ["LogSoftmaxBackward", 451], ["aten::_log_softmax", 447], ["aten::nll_loss_forward", 425], ["aten::ones_like", 410], ["aten::_log_softmax_backward_data", 357], ["aten::zeros_like", 339], ["aten::transpose", 309], ["AddBackward0", 309], ["aten::reshape", 228], ["aten::flatten", 206], ["aten::expand", 141], ["TBackward", 140], ["ViewBackward", 121], ["aten::narrow", 87], ["aten::detach_", 64], ["aten::resize_as_", 54], ["aten::slice", 52], ["aten::conj", 46], ["detach_", 33]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::add_", 96814], ["aten::copy_", 60140], ["aten::cudnn_convolution", 43346], ["aten::mul_", 36843], ["aten::cudnn_convolution_backward_weight", 34576], ["aten::cudnn_convolution_backward_input", 34111], ["aten::cudnn_batch_norm", 33376], ["aten::empty", 33098], ["aten::_cat", 30756], ["aten::div", 26028], ["aten::fill_", 21081], ["aten::cudnn_batch_norm_backward", 20739], ["aten::zero_", 15259], ["aten::add", 14945], ["aten::threshold_backward", 10655], ["aten::cudnn_convolution_backward", 9515], ["aten::threshold_", 9128], ["aten::relu_", 7492], ["torch::autograd::AccumulateGrad", 6798], ["aten::view", 4811], ["aten::to", 4680], ["aten::_convolution", 4514], ["aten::empty_like", 4430], ["CudnnBatchNormBackward", 4303], ["aten::batch_norm", 4032], ["aten::conv2d", 3966], ["aten::convolution", 3855], ["CudnnConvolutionBackward", 3753], ["aten::_batch_norm_impl_index", 3484], ["aten::resize_", 3415], ["aten::set_", 2994], ["aten::permute", 2703], ["ReluBackward1", 2541], ["aten::contiguous", 2069], ["aten::empty_strided", 1725], ["aten::addmm", 1138], ["aten::as_strided", 948], ["aten::unsqueeze", 925], ["aten::mm", 771], ["aten::stack", 596], ["aten::nll_loss_backward", 590], ["aten::max_pool2d_with_indices", 497], ["aten::zeros", 463], ["aten::mean", 431], ["aten::nll_loss_forward", 425], ["aten::t", 355], ["aten::_log_softmax", 343], ["AddBackward0", 309], ["aten::max_pool2d_with_indices_backward", 293], ["aten::_log_softmax_backward_data", 246], ["aten::transpose", 226], ["aten::cat", 199], ["AddmmBackward", 195], ["NllLossBackward", 129], ["aten::expand", 113], ["MeanBackward1", 103], ["aten::ones_like", 100], ["LogSoftmaxBackward", 94], ["aten::max_pool2d", 88], ["aten::adaptive_avg_pool2d", 82], ["aten::log_softmax", 80], ["MaxPool2DWithIndicesBackward", 77], ["aten::nll_loss", 75], ["aten::reshape", 71], ["aten::flatten", 65], ["aten::zeros_like", 53], ["aten::conj", 46], ["aten::resize_as_", 44], ["aten::slice", 41], ["aten::narrow", 35], ["ViewBackward", 34], ["detach_", 33], ["aten::detach_", 31], ["TBackward", 29]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 318, 149670, 149670, 34576, 39006], ["aten::cudnn_convolution_backward_input", 312, 135844, 135844, 34111, 38583], ["aten::cudnn_convolution", 318, 135735, 135735, 43346, 49275], ["aten::cudnn_batch_norm_backward", 318, 56884, 56884, 20739, 27883], ["aten::cudnn_batch_norm", 318, 33292, 33292, 33376, 47638], ["aten::threshold_backward", 294, 26258, 26258, 10655, 12601], ["aten::add_", 2994, 23357, 23357, 96814, 96814], ["aten::threshold_", 294, 17759, 17759, 9128, 9128], ["aten::copy_", 588, 12734, 12734, 60140, 60140], ["aten::max_pool2d_with_indices_backward", 6, 4098, 5046, 293, 686], ["aten::fill_", 978, 2414, 2414, 21081, 21081], ["aten::mul_", 966, 2380, 2380, 36843, 36843], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 497, 644], ["aten::add", 318, 325, 325, 14945, 14945], ["aten::mm", 12, 295, 295, 771, 847], ["aten::mean", 6, 256, 256, 431, 484], ["aten::addmm", 6, 201, 201, 1138, 1274], ["aten::div", 198, 162, 162, 26028, 30671], ["aten::_log_softmax_backward_data", 6, 64, 64, 246, 357], ["aten::_log_softmax", 6, 60, 60, 343, 447], ["aten::nll_loss_forward", 6, 20, 20, 425, 425], ["aten::nll_loss_backward", 6, 18, 18, 590, 590], ["aten::empty", 5748, 0, 0, 33098, 33098], ["aten::zero_", 996, 0, 2408, 15259, 36160], ["aten::zeros", 24, 0, 0, 463, 651], ["aten::set_", 192, 0, 0, 2994, 2994], ["aten::view", 840, 0, 0, 4811, 4811], ["aten::as_strided", 432, 0, 0, 948, 948], ["aten::permute", 192, 0, 0, 2703, 3161], ["aten::empty_like", 534, 0, 0, 4430, 8255], ["aten::contiguous", 192, 0, 0, 2069, 24479], ["aten::empty_strided", 402, 0, 0, 1725, 1725], ["aten::to", 408, 0, 12734, 4680, 46057], ["aten::unsqueeze", 192, 0, 0, 925, 1293], ["aten::resize_", 1926, 0, 0, 3415, 3415], ["aten::slice", 6, 0, 0, 41, 52], ["aten::narrow", 6, 0, 0, 35, 87], ["aten::_cat", 6, 0, 0, 30756, 30970], ["aten::cat", 6, 0, 0, 199, 31169], ["aten::stack", 6, 0, 0, 596, 33058], ["detach_", 6, 0, 0, 33, 33], ["aten::detach_", 6, 0, 0, 31, 64], ["aten::_convolution", 318, 0, 135735, 4514, 53789], ["aten::convolution", 318, 0, 135735, 3855, 57644], ["aten::conv2d", 318, 0, 135735, 3966, 61610], ["aten::_batch_norm_impl_index", 318, 0, 33292, 3484, 51122], ["aten::batch_norm", 318, 0, 33292, 4032, 55154], ["aten::relu_", 294, 0, 17759, 7492, 16620], ["aten::max_pool2d", 6, 0, 1341, 88, 732], ["aten::adaptive_avg_pool2d", 6, 0, 256, 82, 566], ["aten::reshape", 12, 0, 0, 71, 228], ["aten::flatten", 6, 0, 0, 65, 206], ["aten::transpose", 30, 0, 0, 226, 309], ["aten::t", 30, 0, 0, 355, 664], ["aten::expand", 12, 0, 0, 113, 141], ["aten::log_softmax", 6, 0, 60, 80, 527], ["aten::nll_loss", 6, 0, 20, 75, 500], ["aten::ones_like", 6, 0, 6, 100, 410], ["NllLossBackward", 6, 0, 18, 129, 719], ["LogSoftmaxBackward", 6, 0, 64, 94, 451], ["aten::conj", 12, 0, 0, 46, 46], ["AddmmBackward", 6, 0, 295, 195, 1462], ["torch::autograd::AccumulateGrad", 966, 0, 2915, 6798, 34208], ["TBackward", 6, 0, 0, 29, 140], ["ViewBackward", 6, 0, 0, 34, 121], ["MeanBackward1", 6, 0, 162, 103, 606], ["ReluBackward1", 294, 0, 26258, 2541, 15142], ["AddBackward0", 96, 0, 0, 309, 309], ["CudnnBatchNormBackward", 318, 0, 56884, 4303, 32186], ["aten::cudnn_convolution_backward", 318, 0, 285514, 9515, 87104], ["CudnnConvolutionBackward", 318, 0, 285514, 3753, 90857], ["aten::zeros_like", 6, 0, 948, 53, 339], ["aten::resize_as_", 6, 0, 0, 44, 54], ["MaxPool2DWithIndicesBackward", 6, 0, 5046, 77, 763]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 167, 86835, 520, 1084, 330], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 287, 61395, 214, 799, 43], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 104, 53577, 515, 815, 393], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 609, 47050, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3489, 41190, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 90, 40341, 448, 753, 381], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 60, 28063, 468, 851, 361], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 72, 27624, 384, 667, 354], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 34, 27184, 800, 885, 664], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26234, 175, 426, 50], ["volta_sgemm_128x64_nt", 126, 23737, 188, 206, 155], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 48, 21753, 453, 705, 328], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 39, 14259, 366, 370, 361], ["volta_sgemm_128x64_nn", 60, 11407, 190, 207, 156], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 34, 10904, 321, 525, 263], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 8816, 735, 784, 660], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8346, 596, 990, 207], ["volta_scudnn_128x64_relu_interior_nn_v1", 24, 7210, 300, 311, 295], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7058, 42, 87, 14], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5717, 272, 275, 269], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 167, 5482, 33, 158, 6], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5341, 445, 449, 442], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5298, 757, 780, 732], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 123, 5250, 43, 68, 19], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4895, 816, 822, 809], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4781, 683, 684, 682], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 123, 4765, 39, 63, 17], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4312, 308, 325, 299], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3829, 638, 641, 637], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3709, 530, 533, 527], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 3533, 589, 659, 573], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3532, 589, 672, 569], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3395, 283, 296, 270], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2779, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 123, 2617, 21, 66, 4], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2602, 41, 60, 21], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2572, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2449, 39, 61, 16], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2283, 42, 74, 19], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 12, 1699, 142, 184, 98], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1306, 21, 63, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 848, 141, 142, 140], ["volta_scudnn_128x64_stridedB_small_nn_v1", 7, 666, 95, 96, 94], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 131, 330, 3, 4, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 325, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 256, 43, 43, 42], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 154, 198, 1, 2, 1], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 154, 174, 1, 2, 1], ["volta_sgemm_64x32_sliced1x4_nn", 6, 166, 28, 28, 27], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 162, 27, 27, 27], ["volta_sgemm_64x32_sliced1x4_tn", 6, 145, 24, 25, 24], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 39, 135, 3, 5, 3], ["volta_sgemm_128x32_nt", 6, 117, 20, 20, 19], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 83, 90, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 64, 11, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 35, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 33, 6, 6, 5], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 20, 3, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 12, 2, 2, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 86835.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 61395.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 53577.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47050.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41190.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 40341.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 28063.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 27624.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 27184.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26234.0], ["volta_sgemm_128x64_nt", 23737.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 21753.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 14259.0], ["volta_sgemm_128x64_nn", 11407.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 10904.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 8816.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8346.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 7210.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7058.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5717.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5482.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5341.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5298.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 5250.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4895.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4781.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 4765.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4312.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3829.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3709.0], ["void explicit_convolve_sgemm<float, int, 128, 6, 7, 3, 3, 5, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 3533.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3532.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3395.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2779.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2617.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2602.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2572.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2449.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2283.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 1699.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1306.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 848.0], ["volta_scudnn_128x64_stridedB_small_nn_v1", 666.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 330.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 325.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 256.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 198.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 174.0], ["volta_sgemm_64x32_sliced1x4_nn", 166.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 162.0], ["volta_sgemm_64x32_sliced1x4_tn", 145.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 135.0], ["volta_sgemm_128x32_nt", 117.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 90.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 64.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 35.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 33.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 20.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 12.0]]}}
{"steps": {"columns": [{"type": "string", "name": "Step"}, {"type": "number", "name": "Kernel"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memcpy"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Memset"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Runtime"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "DataLoader"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "CPU Exec"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}, {"type": "number", "name": "Other"}, {"type": "string", "role": "tooltip", "p": {"html": "true"}}], "rows": [["5", 134069, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>Kernel: 134069us</b><br>Percentage: 88.36%</div>", 3344, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>Memcpy: 3344us</b><br>Percentage: 2.2%</div>", 76, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>Memset: 76us</b><br>Percentage: 0.05%</div>", 3342, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>Runtime: 3342us</b><br>Percentage: 2.2%</div>", 58, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>DataLoader: 58us</b><br>Percentage: 0.04%</div>", 10091, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>CPU Exec: 10091us</b><br>Percentage: 6.65%</div>", 748, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 5<br>Total: 151728us<br><b>Other: 748us</b><br>Percentage: 0.49%</div>"], ["6", 102836, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>Kernel: 102836us</b><br>Percentage: 87.06%</div>", 3239, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>Memcpy: 3239us</b><br>Percentage: 2.74%</div>", 55, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>Memset: 55us</b><br>Percentage: 0.05%</div>", 2859, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>Runtime: 2859us</b><br>Percentage: 2.42%</div>", 3, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>DataLoader: 3us</b><br>Percentage: 0.0%</div>", 8388, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>CPU Exec: 8388us</b><br>Percentage: 7.1%</div>", 741, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 6<br>Total: 118121us<br><b>Other: 741us</b><br>Percentage: 0.63%</div>"], ["7", 95053, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>Kernel: 95053us</b><br>Percentage: 87.68%</div>", 3218, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>Memcpy: 3218us</b><br>Percentage: 2.97%</div>", 50, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>Memset: 50us</b><br>Percentage: 0.05%</div>", 2518, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>Runtime: 2518us</b><br>Percentage: 2.32%</div>", 15, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>DataLoader: 15us</b><br>Percentage: 0.01%</div>", 6911, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>CPU Exec: 6911us</b><br>Percentage: 6.37%</div>", 646, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 7<br>Total: 108411us<br><b>Other: 646us</b><br>Percentage: 0.6%</div>"], ["8", 105509, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>Kernel: 105509us</b><br>Percentage: 85.01%</div>", 3251, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>Memcpy: 3251us</b><br>Percentage: 2.62%</div>", 57, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>Memset: 57us</b><br>Percentage: 0.05%</div>", 2965, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>Runtime: 2965us</b><br>Percentage: 2.39%</div>", 23, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>DataLoader: 23us</b><br>Percentage: 0.02%</div>", 11606, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>CPU Exec: 11606us</b><br>Percentage: 9.35%</div>", 706, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 8<br>Total: 124117us<br><b>Other: 706us</b><br>Percentage: 0.57%</div>"], ["9", 98896, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>Kernel: 98896us</b><br>Percentage: 85.97%</div>", 3308, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>Memcpy: 3308us</b><br>Percentage: 2.88%</div>", 53, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>Memset: 53us</b><br>Percentage: 0.05%</div>", 2980, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>Runtime: 2980us</b><br>Percentage: 2.59%</div>", 13, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>DataLoader: 13us</b><br>Percentage: 0.01%</div>", 9025, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>CPU Exec: 9025us</b><br>Percentage: 7.85%</div>", 760, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 9<br>Total: 115035us<br><b>Other: 760us</b><br>Percentage: 0.66%</div>"], ["10", 113149, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>Kernel: 113149us</b><br>Percentage: 74.4%</div>", 3361, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>Memcpy: 3361us</b><br>Percentage: 2.21%</div>", 60, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>Memset: 60us</b><br>Percentage: 0.04%</div>", 2897, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>Runtime: 2897us</b><br>Percentage: 1.91%</div>", 16, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>DataLoader: 16us</b><br>Percentage: 0.01%</div>", 8527, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>CPU Exec: 8527us</b><br>Percentage: 5.61%</div>", 24062, "<div class=\"visualization-tooltip\" style=\"white-space: nowrap;\">Step 10<br>Total: 152072us<br><b>Other: 24062us</b><br>Percentage: 15.82%</div>"]]}, "performance": [{"name": "Average Step Time", "description": "", "value": 128247, "extra": 100, "children": [{"name": "Kernel", "description": "", "value": 108252, "extra": 84.41}, {"name": "Memcpy", "description": "", "value": 3287, "extra": 2.56}, {"name": "Memset", "description": "", "value": 58, "extra": 0.05}, {"name": "Runtime", "description": "", "value": 2927, "extra": 2.28}, {"name": "DataLoader", "description": "", "value": 21, "extra": 0.02}, {"name": "CPU Exec", "description": "", "value": 9091, "extra": 7.09}, {"name": "Other", "description": "", "value": 4610, "extra": 3.6}]}], "recommendations": "<ul><li>N/A</li></ul>", "environments": [{"title": "Number of Worker(s)", "value": "1"}, {"title": "Device Type", "value": "GPU"}, {"title": "Number of Device(s)", "value": "1"}]}
{"device_total_time": {"title": "Device Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward", 288342], ["CudnnConvolutionBackward", 288342], ["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::_convolution", 134544], ["aten::convolution", 134544], ["aten::conv2d", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["CudnnBatchNormBackward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::_batch_norm_impl_index", 33334], ["aten::batch_norm", 33334], ["aten::threshold_backward", 26280], ["ReluBackward1", 26280], ["aten::add_", 23354], ["aten::to", 19721], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::relu_", 17770], ["aten::max_pool2d_with_indices_backward", 5053], ["MaxPool2DWithIndicesBackward", 5053], ["torch::autograd::AccumulateGrad", 2918], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::zero_", 2370], ["aten::max_pool2d_with_indices", 1341], ["aten::max_pool2d", 1341], ["aten::zeros_like", 948], ["aten::add", 327], ["aten::mm", 288], ["AddmmBackward", 288], ["aten::mean", 258], ["aten::adaptive_avg_pool2d", 258], ["aten::addmm", 204], ["aten::div", 161], ["MeanBackward1", 161], ["aten::_log_softmax_backward_data", 63], ["LogSoftmaxBackward", 63], ["aten::_log_softmax", 60], ["aten::log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss", 21], ["aten::nll_loss_backward", 19], ["NllLossBackward", 19], ["aten::ones_like", 6]]}, "device_self_time": {"title": "Device Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::cudnn_convolution_backward_weight", 151977], ["aten::cudnn_convolution_backward_input", 136365], ["aten::cudnn_convolution", 134544], ["aten::cudnn_batch_norm_backward", 56960], ["aten::cudnn_batch_norm", 33334], ["aten::threshold_backward", 26280], ["aten::add_", 23354], ["aten::copy_", 19721], ["aten::threshold_", 17770], ["aten::max_pool2d_with_indices_backward", 4105], ["aten::fill_", 2376], ["aten::mul_", 2376], ["aten::max_pool2d_with_indices", 1341], ["aten::add", 327], ["aten::mm", 288], ["aten::mean", 258], ["aten::addmm", 204], ["aten::div", 161], ["aten::_log_softmax_backward_data", 63], ["aten::_log_softmax", 60], ["aten::nll_loss_forward", 21], ["aten::nll_loss_backward", 19]]}, "host_total_time": {"title": "Host Total Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::to", 95877], ["aten::copy_", 95330], ["CudnnConvolutionBackward", 89870], ["aten::add_", 88364], ["aten::cudnn_convolution_backward", 85929], ["aten::conv2d", 60800], ["aten::convolution", 56995], ["aten::batch_norm", 53643], ["aten::_convolution", 53318], ["aten::_batch_norm_impl_index", 50036], ["aten::cudnn_convolution", 48860], ["aten::cudnn_batch_norm", 46680], ["torch::autograd::AccumulateGrad", 43241], ["aten::cudnn_convolution_backward_input", 39025], ["aten::cudnn_convolution_backward_weight", 37464], ["CudnnBatchNormBackward", 34153], ["aten::mul_", 32585], ["aten::zero_", 32441], ["aten::cudnn_batch_norm_backward", 29705], ["aten::empty", 29598], ["aten::fill_", 19488], ["aten::relu_", 16391], ["ReluBackward1", 15546], ["aten::add", 14077], ["aten::threshold_backward", 13019], ["aten::threshold_", 8921], ["aten::empty_like", 6343], ["aten::resize_", 3854], ["aten::view", 2824], ["AddmmBackward", 1508], ["aten::addmm", 1219], ["aten::mm", 857], ["MaxPool2DWithIndicesBackward", 779], ["NllLossBackward", 737], ["aten::t", 714], ["aten::max_pool2d", 709], ["aten::max_pool2d_with_indices_backward", 699], ["aten::zeros", 625], ["aten::max_pool2d_with_indices", 622], ["MeanBackward1", 615], ["aten::nll_loss_backward", 604], ["aten::adaptive_avg_pool2d", 530], ["aten::log_softmax", 513], ["aten::nll_loss", 504], ["LogSoftmaxBackward", 454], ["aten::mean", 449], ["aten::_log_softmax", 434], ["aten::nll_loss_forward", 430], ["aten::div", 426], ["aten::_log_softmax_backward_data", 383], ["aten::ones_like", 381], ["AddBackward0", 337], ["aten::transpose", 331], ["aten::zeros_like", 331], ["aten::empty_strided", 319], ["aten::reshape", 223], ["aten::flatten", 187], ["TBackward", 174], ["aten::expand", 150], ["ViewBackward", 130], ["aten::as_strided", 128], ["aten::set_", 118], ["aten::detach_", 95], ["aten::resize_as_", 60], ["aten::conj", 53], ["detach_", 32]]}, "host_self_time": {"title": "Host Self Time", "columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["aten::copy_", 95330], ["aten::add_", 88364], ["aten::cudnn_convolution", 43392], ["aten::cudnn_convolution_backward_input", 34542], ["aten::mul_", 32585], ["aten::cudnn_convolution_backward_weight", 32463], ["aten::cudnn_batch_norm", 32170], ["aten::empty", 29598], ["aten::cudnn_batch_norm_backward", 22529], ["aten::fill_", 19488], ["aten::add", 14077], ["aten::zero_", 13103], ["torch::autograd::AccumulateGrad", 12619], ["aten::threshold_backward", 11098], ["aten::cudnn_convolution_backward", 9440], ["aten::threshold_", 8921], ["aten::relu_", 7470], ["aten::_convolution", 4458], ["CudnnBatchNormBackward", 4448], ["CudnnConvolutionBackward", 3941], ["aten::resize_", 3854], ["aten::conv2d", 3805], ["aten::convolution", 3677], ["aten::batch_norm", 3607], ["aten::empty_like", 3452], ["aten::_batch_norm_impl_index", 3356], ["aten::view", 2824], ["ReluBackward1", 2527], ["aten::addmm", 1079], ["aten::mm", 778], ["aten::nll_loss_backward", 604], ["aten::max_pool2d_with_indices", 482], ["aten::zeros", 465], ["aten::nll_loss_forward", 430], ["aten::mean", 401], ["aten::div", 384], ["aten::t", 383], ["aten::_log_softmax", 340], ["AddBackward0", 337], ["aten::empty_strided", 319], ["aten::max_pool2d_with_indices_backward", 308], ["aten::to", 300], ["aten::_log_softmax_backward_data", 262], ["aten::transpose", 233], ["AddmmBackward", 213], ["NllLossBackward", 133], ["aten::as_strided", 128], ["aten::expand", 120], ["aten::set_", 118], ["aten::max_pool2d", 87], ["MeanBackward1", 87], ["aten::ones_like", 85], ["aten::adaptive_avg_pool2d", 81], ["MaxPool2DWithIndicesBackward", 80], ["aten::log_softmax", 79], ["aten::nll_loss", 74], ["LogSoftmaxBackward", 71], ["aten::reshape", 70], ["aten::detach_", 63], ["aten::flatten", 59], ["aten::zeros_like", 54], ["aten::conj", 53], ["aten::resize_as_", 49], ["TBackward", 43], ["ViewBackward", 35], ["detach_", 32]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Device Self Duration (us)"}, {"type": "number", "name": "Device Total Duration (us)"}, {"type": "number", "name": "Host Self Duration (us)"}, {"type": "number", "name": "Host Total Duration (us)"}], "rows": [["aten::cudnn_convolution_backward_weight", 318, 151977, 151977, 32463, 37464], ["aten::cudnn_convolution_backward_input", 312, 136365, 136365, 34542, 39025], ["aten::cudnn_convolution", 318, 134544, 134544, 43392, 48860], ["aten::cudnn_batch_norm_backward", 318, 56960, 56960, 22529, 29705], ["aten::cudnn_batch_norm", 318, 33334, 33334, 32170, 46680], ["aten::threshold_backward", 294, 26280, 26280, 11098, 13019], ["aten::add_", 2994, 23354, 23354, 88364, 88364], ["aten::copy_", 12, 19721, 19721, 95330, 95330], ["aten::threshold_", 294, 17770, 17770, 8921, 8921], ["aten::max_pool2d_with_indices_backward", 6, 4105, 5053, 308, 699], ["aten::fill_", 978, 2376, 2376, 19488, 19488], ["aten::mul_", 966, 2376, 2376, 32585, 32585], ["aten::max_pool2d_with_indices", 6, 1341, 1341, 482, 622], ["aten::add", 318, 327, 327, 14077, 14077], ["aten::mm", 12, 288, 288, 778, 857], ["aten::mean", 6, 258, 258, 401, 449], ["aten::addmm", 6, 204, 204, 1079, 1219], ["aten::div", 6, 161, 161, 384, 426], ["aten::_log_softmax_backward_data", 6, 63, 63, 262, 383], ["aten::_log_softmax", 6, 60, 60, 340, 434], ["aten::nll_loss_forward", 6, 21, 21, 430, 430], ["aten::nll_loss_backward", 6, 19, 19, 604, 604], ["aten::empty", 5172, 0, 0, 29598, 29598], ["aten::zero_", 996, 0, 2370, 13103, 32441], ["aten::zeros", 24, 0, 0, 465, 625], ["aten::to", 30, 0, 19721, 300, 95877], ["detach_", 12, 0, 0, 32, 32], ["aten::detach_", 12, 0, 0, 63, 95], ["aten::set_", 12, 0, 0, 118, 118], ["aten::empty_strided", 18, 0, 0, 319, 319], ["aten::resize_", 1920, 0, 0, 3854, 3854], ["aten::_convolution", 318, 0, 134544, 4458, 53318], ["aten::convolution", 318, 0, 134544, 3677, 56995], ["aten::conv2d", 318, 0, 134544, 3805, 60800], ["aten::empty_like", 342, 0, 0, 3452, 6343], ["aten::view", 648, 0, 0, 2824, 2824], ["aten::_batch_norm_impl_index", 318, 0, 33334, 3356, 50036], ["aten::batch_norm", 318, 0, 33334, 3607, 53643], ["aten::relu_", 294, 0, 17770, 7470, 16391], ["aten::max_pool2d", 6, 0, 1341, 87, 709], ["aten::adaptive_avg_pool2d", 6, 0, 258, 81, 530], ["aten::reshape", 12, 0, 0, 70, 223], ["aten::flatten", 6, 0, 0, 59, 187], ["aten::as_strided", 42, 0, 0, 128, 128], ["aten::transpose", 30, 0, 0, 233, 331], ["aten::t", 30, 0, 0, 383, 714], ["aten::expand", 12, 0, 0, 120, 150], ["aten::log_softmax", 6, 0, 60, 79, 513], ["aten::nll_loss", 6, 0, 21, 74, 504], ["aten::ones_like", 6, 0, 6, 85, 381], ["NllLossBackward", 6, 0, 19, 133, 737], ["LogSoftmaxBackward", 6, 0, 63, 71, 454], ["aten::conj", 12, 0, 0, 53, 53], ["AddmmBackward", 6, 0, 288, 213, 1508], ["torch::autograd::AccumulateGrad", 966, 0, 2918, 12619, 43241], ["TBackward", 6, 0, 0, 43, 174], ["ViewBackward", 6, 0, 0, 35, 130], ["MeanBackward1", 6, 0, 161, 87, 615], ["ReluBackward1", 294, 0, 26280, 2527, 15546], ["AddBackward0", 96, 0, 0, 337, 337], ["CudnnBatchNormBackward", 318, 0, 56960, 4448, 34153], ["aten::cudnn_convolution_backward", 318, 0, 288342, 9440, 85929], ["CudnnConvolutionBackward", 318, 0, 288342, 3941, 89870], ["aten::zeros_like", 6, 0, 948, 54, 331], ["aten::resize_as_", 6, 0, 0, 49, 60], ["MaxPool2DWithIndicesBackward", 6, 0, 5053, 80, 779]]}}
{"data": {"columns": [{"type": "string", "name": "Name"}, {"type": "number", "name": "Calls"}, {"type": "number", "name": "Total Duration (us)"}, {"type": "number", "name": "Mean Duration (us)"}, {"type": "number", "name": "Max Duration (us)"}, {"type": "number", "name": "Min Duration (us)"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 178, 90214, 507, 1092, 154], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 179, 85427, 477, 814, 381], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 292, 62347, 214, 802, 43], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 613, 47476, 77, 364, 6], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 3506, 41486, 12, 364, 1], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 84, 36210, 431, 753, 384], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 66, 32761, 496, 854, 362], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 150, 26289, 175, 433, 50], ["volta_sgemm_128x64_nt", 126, 23803, 189, 205, 156], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 49, 22477, 459, 705, 329], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 21, 18728, 892, 913, 881], ["volta_sgemm_128x64_nn", 78, 14530, 186, 207, 157], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 35, 11515, 329, 528, 260], ["volta_scudnn_128x64_relu_interior_nn_v1", 30, 10280, 343, 530, 295], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 14, 8372, 598, 993, 207], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 21, 7728, 368, 377, 365], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 141, 7213, 51, 115, 20], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 141, 7133, 51, 143, 17], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 168, 7045, 42, 87, 14], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 178, 5920, 33, 158, 6], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 21, 5763, 274, 294, 269], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 12, 5352, 446, 449, 443], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 7, 5335, 762, 781, 744], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 6, 4882, 814, 817, 811], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 7, 4795, 685, 690, 683], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 7, 4662, 666, 669, 658], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 14, 4373, 312, 327, 297], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 4023, 670, 676, 663], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 6, 4007, 668, 672, 664], ["volta_scudnn_128x64_relu_medium_nn_v1", 6, 3850, 642, 644, 638], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 6, 3731, 622, 672, 571], ["volta_scudnn_128x128_stridedB_small_nn_v1", 7, 3726, 532, 542, 526], ["volta_scudnn_128x64_relu_small_nn_v1", 12, 3427, 286, 295, 272], ["volta_scudnn_128x128_relu_interior_nn_v1", 6, 3340, 557, 562, 551], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 1127, 2771, 2, 24, 1], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 141, 2699, 19, 66, 3], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 63, 2540, 40, 60, 20], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 979, 2534, 3, 158, 0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 63, 2479, 39, 60, 18], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 54, 2313, 43, 74, 19], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 6, 1341, 224, 224, 223], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 63, 1320, 21, 65, 4], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 6, 864, 144, 147, 142], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 6, 601, 100, 101, 99], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 137, 352, 3, 6, 2], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 318, 327, 1, 2, 1], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 6, 258, 43, 43, 43], ["volta_sgemm_64x32_sliced1x4_nn", 6, 161, 27, 27, 26], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 6, 161, 27, 27, 26], ["volta_sgemm_64x32_sliced1x4_tn", 6, 144, 24, 24, 24], ["volta_sgemm_128x32_nt", 6, 115, 19, 20, 19], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 62, 87, 1, 2, 1], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 77, 85, 1, 2, 1], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 21, 84, 4, 4, 4], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 62, 75, 1, 2, 1], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 6, 63, 10, 11, 10], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 6, 60, 10, 10, 10], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 6, 48, 8, 8, 8], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 12, 36, 3, 4, 2], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 6, 36, 6, 6, 6], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 6, 21, 4, 4, 3], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 6, 13, 2, 3, 2]]}}
{"total": {"columns": [{"type": "string", "name": "name"}, {"type": "number", "name": "value"}], "rows": [["void cudnn::detail::dgrad_engine<float, 512, 6, 5, 3, 3, 3, false>(int, int, int, float const*, int, float const*, int, float*, kernel_grad_params, unsigned long long, int, unsigned long long, int, float, int, int, int)", 90214.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 7, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 85427.0], ["void cudnn::bn_bw_1C11_kernel_new<float, float, float2, 512, true, 1>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float)", 62347.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::threshold_kernel_impl<float>(at::TensorIterator&, float, float)::{lambda(float, float)#1}, at::detail::Array<char*, 3>)", 47476.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::AddFunctor<float>, at::detail::Array<char*, 3> >(int, at::native::AddFunctor<float>, at::detail::Array<char*, 3>)", 41486.0], ["void implicit_convolve_sgemm<float, float, 1024, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 36210.0], ["void implicit_convolve_sgemm<float, float, 128, 6, 7, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 32761.0], ["void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, 512, true, 1>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float)", 26289.0], ["volta_sgemm_128x64_nt", 23803.0], ["volta_scudnn_128x128_stridedB_splitK_small_nn_v1", 22477.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 512, 6, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 18728.0], ["volta_sgemm_128x64_nn", 14530.0], ["volta_scudnn_128x64_stridedB_interior_nn_v1", 11515.0], ["volta_scudnn_128x64_relu_interior_nn_v1", 10280.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 5, 5, 3, 3, 3, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 8372.0], ["volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1", 7728.0], ["void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)", 7213.0], ["void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 7133.0], ["void cudnn::bn_fw_tr_1C11_singleread<float, 512, true, 1, 2, 0>(cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float const*, float, float, float*, float*, float*, float*, float, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)", 7045.0], ["void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)", 5920.0], ["volta_scudnn_128x128_stridedB_interior_nn_v1", 5763.0], ["void implicit_convolve_sgemm<float, float, 128, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 5352.0], ["void cudnn::cnn::wgrad_alg0_engine<float, 128, 6, 8, 3, 3, 5, false, 512>(int, int, int, float const*, int, float*, float const*, kernel_grad_params, unsigned long long, int, float, int, int, int, int)", 5335.0], ["void explicit_convolve_sgemm<float, int, 1024, 5, 5, 3, 3, 3, 0, false>(int, int, int, float const*, int, float const*, int, float*, kernel_conv_params, unsigned long long, int, unsigned long long, int, float, float, int, float const*, float const*)", 4882.0], ["void at::native::(anonymous namespace)::max_pool_backward_nchw<float, float>(int, float const*, long const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*)", 4795.0], ["volta_scudnn_128x128_stridedB_splitK_medium_nn_v1", 4662.0], ["volta_scudnn_128x128_stridedB_medium_nn_v1", 4373.0], ["void implicit_convolve_sgemm<float, float, 512, 6, 8, 3, 3, 5, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 4023.0], ["volta_scudnn_128x64_stridedB_splitK_xregs_large_nn_v1", 4007.0], ["volta_scudnn_128x64_relu_medium_nn_v1", 3850.0], ["volta_scudnn_128x64_relu_xregs_large_nn_v1", 3731.0], ["volta_scudnn_128x128_stridedB_small_nn_v1", 3726.0], ["volta_scudnn_128x64_relu_small_nn_v1", 3427.0], ["volta_scudnn_128x128_relu_interior_nn_v1", 3340.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2> >(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>)", 2771.0], ["void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)", 2699.0], ["void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)", 2540.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)", 2534.0], ["void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)", 2479.0], ["void cudnn::bn_bw_1C11_singleread<float, 512, true, 1, 2, 0>(float, float, float, float, cudnnTensorStruct, float const*, cudnnTensorStruct, float const*, cudnnTensorStruct, float*, float const*, float*, float*, float const*, float const*, float, cudnn::reduced_divisor, int, cudnn::reduced_divisor, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)", 2313.0], ["void at::native::(anonymous namespace)::max_pool_forward_nchw<float, float>(int, float const*, int, int, int, int, int, int, int, int, int, int, int, int, int, int, float*, long*)", 1341.0], ["void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)", 1320.0], ["void implicit_convolve_sgemm<float, float, 1024, 5, 5, 3, 3, 3, 1, false, true, true>(int, int, int, float const*, int, float*, float const*, kernel_conv_params, unsigned long long, int, float, float, int, float const*, float const*, bool, int, int)", 864.0], ["void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const*, float*)", 601.0], ["cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)", 352.0], ["void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<at::native::AddFunctor<long> >, at::detail::Array<char*, 2>)", 327.0], ["void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, 4>)", 258.0], ["volta_sgemm_64x32_sliced1x4_nn", 161.0], ["void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, OffsetCalculator<1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast)", 161.0], ["volta_sgemm_64x32_sliced1x4_tn", 144.0], ["volta_sgemm_128x32_nt", 115.0], ["cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)", 87.0], ["cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)", 85.0], ["void cudnn::winograd::generateWinogradTilesKernel<0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)", 84.0], ["cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)", 75.0], ["void (anonymous namespace)::softmax_warp_backward<float, float, float, 10, true>(float*, float const*, float const*, int, int, int)", 63.0], ["void (anonymous namespace)::softmax_warp_forward<float, float, float, 10, true>(float*, float const*, int, int, int)", 60.0], ["void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)", 48.0], ["void splitKreduce_kernel<float, float, float>(cublasSplitKParams<float>, float const*, float const*, float*, float const*, float const*)", 36.0], ["void at::native::unrolled_elementwise_kernel<at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast>(int, at::native::copy_device_to_device(at::TensorIterator&, bool)::{lambda()#2}::operator()() const::{lambda()#8}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, OffsetCalculator<1, unsigned int>, char*, at::native::memory::LoadWithoutCast, at::detail::Array<char*, 2>::StoreWithoutCast)", 36.0], ["void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)", 21.0], ["void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)", 13.0]]}}
